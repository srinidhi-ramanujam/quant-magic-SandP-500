"""
Hybrid retrieval utilities for entities and template intents.

Loads FAISS indexes + metadata generated by scripts/build_vector_store.py
and provides lightweight helpers for embedding-based lookup.
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass
import os
from functools import lru_cache
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

try:
    from src.telemetry import get_logger
except Exception:  # pragma: no cover - fallback for early import
    get_logger = lambda: logging.getLogger(__name__)


LOGGER = get_logger()

ROOT = Path(__file__).resolve().parents[1]
ARTIFACT_DIR = ROOT / "artifacts" / "vector_store"
MANIFEST_PATH = ARTIFACT_DIR / "manifest.json"
ENTITY_INDEX_PATH = ARTIFACT_DIR / "entities.index"
ENTITY_METADATA_PATH = ARTIFACT_DIR / "entities_metadata.json"
TEMPLATE_INDEX_PATH = ARTIFACT_DIR / "templates.index"
TEMPLATE_METADATA_PATH = ARTIFACT_DIR / "templates_metadata.json"

DEFAULT_THRESHOLD = 0.55
DEFAULT_TEMPLATE_THRESHOLD = 0.6
TOP_K = 16


def _load_json(path: Path) -> Any:
    if not path.exists():
        raise FileNotFoundError(f"Required artifact missing: {path}")
    return json.loads(path.read_text())


@lru_cache(maxsize=1)
def _load_manifest() -> Dict[str, Any]:
    return _load_json(MANIFEST_PATH)


@lru_cache(maxsize=1)
def _load_encoder(model_name: str) -> SentenceTransformer:
    LOGGER.info("Loading embedding model: %s", model_name)
    try:
        return SentenceTransformer(model_name)
    except Exception as exc:  # pragma: no cover - safety for offline envs
        LOGGER.warning("Unable to load embedding model %s: %s", model_name, exc)
        raise RuntimeError(f"Failed to load embedding model: {model_name}") from exc


def _encode_texts(encoder: SentenceTransformer, texts: List[str]) -> np.ndarray:
    embeddings = encoder.encode(
        texts,
        batch_size=32,
        convert_to_numpy=True,
        normalize_embeddings=False,
    )
    return _normalize(embeddings)


def _normalize(vectors: np.ndarray) -> np.ndarray:
    vectors = vectors.astype("float32")
    faiss.normalize_L2(vectors)
    return vectors


class VectorIndex:
    """Wrapper around a FAISS index + metadata list."""

    def __init__(self, index_path: Path, metadata_path: Path):
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.index = faiss.read_index(str(index_path))
        self.metadata: List[Dict[str, Any]] = _load_json(metadata_path)

    def search(self, query_vector: np.ndarray, top_k: int) -> Tuple[np.ndarray, np.ndarray]:
        return self.index.search(query_vector, top_k)


@dataclass
class TemplateRetrievalResult:
    template_id: str
    score: float
    metadata: Dict[str, Any]


class HybridEntityRetriever:
    """Embed-based entity slot retriever."""

    def __init__(self, encoder: SentenceTransformer, index: VectorIndex):
        self.encoder = encoder
        self.index = index
        self.slot_thresholds = {
            "sector": 0.60,
            "metric": 0.60,
            "question_type": 0.55,
        }

    @classmethod
    def create_default(cls) -> Optional["HybridEntityRetriever"]:
        if _is_flag_enabled("DISABLE_HYBRID_RETRIEVER"):
            LOGGER.info("Hybrid entity retriever disabled via env flag")
            return None
        try:
            manifest = _load_manifest()
            encoder = _load_encoder(manifest["model"])
            index = VectorIndex(ENTITY_INDEX_PATH, ENTITY_METADATA_PATH)
            LOGGER.info("Hybrid entity retriever enabled (vectors=%s)", manifest["entity_vectors"])
            return cls(encoder, index)
        except FileNotFoundError:
            LOGGER.warning("Hybrid entity retriever artifacts not found; skipping")
        except Exception as exc:  # pragma: no cover - defensive
            LOGGER.warning("Failed to initialize hybrid entity retriever: %s", exc)
        return None

    def enrich(self, question: str, entities: Any) -> Dict[str, Any]:
        """Attempt to fill missing slots on ExtractedEntities."""
        if not question.strip():
            return {}

        vector = self._encode_question(question)
        scores, idxs = self.index.search(vector, TOP_K)
        slot_updates: Dict[str, Any] = {}

        # sectors
        if not entities.sectors:
            match = self._best_for_slot("sector", scores[0], idxs[0])
            if match:
                entities.sectors = [match["canonical"]]
                slot_updates["sector"] = match["canonical"]

        if not entities.metrics:
            match = self._best_for_slot("metric", scores[0], idxs[0])
            if match:
                entities.metrics = [match["canonical"]]
                slot_updates["metric"] = match["canonical"]

        if not entities.question_type:
            match = self._best_for_slot("question_type", scores[0], idxs[0])
            if match:
                entities.question_type = match["canonical"]
                slot_updates["question_type"] = match["canonical"]

        return slot_updates

    def _encode_question(self, question: str) -> np.ndarray:
        vec = self.encoder.encode(
            [question],
            convert_to_numpy=True,
            normalize_embeddings=False,
        )
        return _normalize(vec)

    def _best_for_slot(
        self,
        slot: str,
        scores: np.ndarray,
        indices: np.ndarray,
    ) -> Optional[Dict[str, Any]]:
        threshold = self.slot_thresholds.get(slot, DEFAULT_THRESHOLD)
        for score, idx in zip(scores, indices):
            if idx < 0 or idx >= len(self.index.metadata):
                continue
            meta = self.index.metadata[idx]
            if meta.get("slot") == slot and score >= threshold:
                return {
                    **meta,
                    "score": float(score),
                }
        return None


class TemplateIntentRetriever:
    """Embed-based template selector."""

    def __init__(self, encoder: SentenceTransformer, index: VectorIndex):
        self.encoder = encoder
        self.index = index

    @classmethod
    def create_default(cls) -> Optional["TemplateIntentRetriever"]:
        if _is_flag_enabled("DISABLE_TEMPLATE_RETRIEVER"):
            LOGGER.info("Template intent retriever disabled via env flag")
            return None
        try:
            manifest = _load_manifest()
            encoder = _load_encoder(manifest["model"])
            index = VectorIndex(TEMPLATE_INDEX_PATH, TEMPLATE_METADATA_PATH)
            LOGGER.info(
                "Template intent retriever enabled (vectors=%s)",
                manifest["template_vectors"],
            )
            return cls(encoder, index)
        except FileNotFoundError:
            LOGGER.warning("Template intent artifacts not found; skipping")
        except Exception as exc:  # pragma: no cover - defensive
            LOGGER.warning("Failed to initialize template retriever: %s", exc)
        return None

    def retrieve(self, question: str, top_k: int = TOP_K) -> Optional[TemplateRetrievalResult]:
        if not question.strip():
            return None
        vector = self._encode_question(question)
        scores, idxs = self.index.search(vector, top_k)
        for score, idx in zip(scores[0], idxs[0]):
            if idx < 0 or idx >= len(self.index.metadata):
                continue
            if score < DEFAULT_TEMPLATE_THRESHOLD:
                continue
            meta = self.index.metadata[idx]
            template_id = meta.get("template_id")
            if not template_id:
                continue
            return TemplateRetrievalResult(
                template_id=template_id,
                score=float(score),
                metadata=meta.get("metadata", {}),
            )
        return None

    def _encode_question(self, question: str) -> np.ndarray:
        vec = self.encoder.encode(
            [question],
            convert_to_numpy=True,
            normalize_embeddings=False,
        )
        return _normalize(vec)
def _is_flag_enabled(flag_name: str) -> bool:
    return os.getenv(flag_name, "").strip().lower() in {"1", "true", "yes"}
