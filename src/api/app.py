"""FastAPI entrypoint for Quant Magic."""

from __future__ import annotations

from typing import Any, Dict, Optional

from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field

from src.llm_guard import (
    LLMAvailabilityError,
    OFFLINE_FALLBACK_HELP,
    ensure_llm_available,
)
from src.models import FormattedResponse, QueryRequest
from src.session_logger import log_interaction
from src.services import QueryService, QueryServiceResult


_DEBUG_SENTINEL = object()


class QueryResponseModel(BaseModel):
    """Shape of responses returned by the query endpoint."""

    answer: str = Field(
        ..., description="Natural language answer generated by the pipeline."
    )
    success: bool = Field(
        ..., description="Indicates whether the pipeline completed successfully."
    )
    sql: Optional[str] = Field(
        default=None, description="SQL executed for the question (if available)."
    )
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description="Telemetry, timing, and contextual metadata about the request.",
    )
    sources: Optional[list[str]] = Field(
        default=None, description="Underlying data sources referenced."
    )
    debug: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Debug artefacts when debug mode is enabled.",
    )
    error: Optional[str] = Field(
        default=None,
        description="Pipeline error message when success is False.",
    )
    presentation: Optional[Dict[str, Any]] = Field(
        default=None, description="Optional polished presentation payload."
    )
    reasoning_trace: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Structured reasoning trace describing template + row counts.",
    )
    sql_collapsible_hint: Optional[str] = Field(
        default=None,
        description="Short summary displayed next to the SQL toggle in the UI.",
    )

    @classmethod
    def from_service_result(
        cls,
        result: QueryServiceResult,
        response: FormattedResponse,
        *,
        debug: Any = _DEBUG_SENTINEL,
    ) -> "QueryResponseModel":
        """Translate service result into API response payload."""

        metadata = dict(response.metadata or {})
        metadata.setdefault("request_id", result.context.request_id)
        metadata.setdefault("total_time_seconds", round(result.context.elapsed(), 4))
        metadata["component_timings"] = result.context.component_timings

        if result.query_result:
            metadata.setdefault("row_count", result.query_result.row_count)

        return cls(
            answer=response.answer,
            success=response.success,
            sql=result.query_result.sql_executed if result.query_result else None,
            metadata=metadata,
            sources=response.sources or None,
            debug=response.debug_info if debug is _DEBUG_SENTINEL else debug,
            error=response.error,
            presentation=response.presentation.model_dump()
            if response.presentation
            else None,
            reasoning_trace=response.reasoning_trace.model_dump()
            if response.reasoning_trace
            else None,
            sql_collapsible_hint=_build_sql_hint(result),
        )


def _build_sql_hint(result: QueryServiceResult) -> Optional[str]:
    """Generate a concise summary for the SQL toggle."""
    generated = result.generated_sql
    if not generated:
        return None

    parts: list[str] = []
    if generated.template_id:
        parts.append(f"template `{generated.template_id}`")
    elif generated.generation_method:
        parts.append(generated.generation_method)

    if result.query_result:
        parts.append(f"{result.query_result.row_count} rows")

    return " Â· ".join(parts) if parts else None


app = FastAPI(
    title="Quant Magic API",
    description="Natural language to SQL pipeline over S&P 500 financial data.",
    version="0.1.0",
)

_service_instance: Optional[QueryService] = None
_service_override: Optional[QueryService] = None


def _resolve_query_service() -> QueryService:
    """Resolve cached service, honoring test overrides."""
    global _service_instance, _service_override
    if _service_override is not None:
        return _service_override

    if _service_instance is None:
        _service_instance = QueryService()
    return _service_instance


def set_query_service_override(service: Optional[QueryService]) -> None:
    """Allow tests to inject a custom QueryService."""
    global _service_override, _service_instance
    _service_override = service
    if service is None:
        _service_instance = None


def _llm_health_status() -> tuple[bool, str]:
    """Check Azure OpenAI availability for health endpoints."""
    try:
        ensure_llm_available("FastAPI health check")
    except LLMAvailabilityError as exc:
        return False, f"{exc}. {OFFLINE_FALLBACK_HELP}"
    return True, "LLM available"


@app.get("/health", tags=["system"])
async def healthcheck() -> Dict[str, Any]:
    """Return JSON health + LLM availability information."""
    available, message = _llm_health_status()
    status = "ok" if available else "degraded"
    return {
        "status": status,
        "llm_available": available,
        "message": message,
    }


@app.get("/health/snippet", response_class=HTMLResponse, tags=["system"])
async def healthcheck_snippet() -> str:
    """Return an HTML snippet consumed by the UI via HTMX."""
    available, message = _llm_health_status()
    label = "API available" if available else "API unavailable"
    badge_color = "bg-emerald-400" if available else "bg-red-500"
    text_color = "text-emerald-300" if available else "text-red-200"
    detail = "" if available else message
    indicator = (
        f'<span class="h-2.5 w-2.5 rounded-full {badge_color} animate-pulse"></span>'
    )
    content = (
        f'<div class="flex flex-col gap-1 text-sm {text_color}">'
        f"<div class='flex items-center gap-2'>{indicator}"
        f"<span class='font-semibold tracking-wide uppercase'>{label}</span>"
        "</div>"
        f"<p class='text-xs text-slate-400'>{detail}</p>"
        "</div>"
    )
    return content


@app.post("/query", response_model=QueryResponseModel, tags=["query"])
async def run_query(request: QueryRequest) -> QueryResponseModel:
    """Execute the core pipeline via HTTP."""
    try:
        service = _resolve_query_service()
    except LLMAvailabilityError as exc:
        raise HTTPException(
            status_code=503,
            detail=f"{exc}. {OFFLINE_FALLBACK_HELP}",
        ) from exc

    try:
        result = service.run(
            request.question,
            debug_mode=request.debug_mode,
            history=request.history,
            include_presentation=request.include_formatted_answer,
        )
    except LLMAvailabilityError as exc:
        raise HTTPException(
            status_code=503,
            detail=f"{exc}. {OFFLINE_FALLBACK_HELP}",
        ) from exc

    response = result.response
    log_interaction(
        channel="api",
        question=request.question,
        response=response,
        context=result.context,
        entities=result.entities,
        generated_sql=result.generated_sql,
        debug_mode=request.debug_mode,
    )

    debug_payload = response.debug_info if request.debug_mode else None
    return QueryResponseModel.from_service_result(result, response, debug=debug_payload)


@app.on_event("shutdown")
def _shutdown() -> None:  # pragma: no cover - FastAPI lifecycle hook
    """Close resources when the application exits."""
    global _service_instance
    if _service_instance:
        _service_instance.close()
        _service_instance = None


__all__ = ["app", "set_query_service_override"]
